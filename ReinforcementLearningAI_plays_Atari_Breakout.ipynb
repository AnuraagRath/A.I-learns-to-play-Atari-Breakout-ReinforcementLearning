{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8a77191-8575-4bb6-9872-c29df4f0024b",
   "metadata": {},
   "source": [
    "# Importing the Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0033ed1-20f5-499b-8aa8-72bdb171c8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gym\n",
    "from stable_baselines3 import A2C\n",
    "from stable_baselines3.common.vec_env import VecFrameStack\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.env_util import make_atari_env"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5e3c4d-23ab-49c1-8654-d6e294cbd4ad",
   "metadata": {},
   "source": [
    "# Test Env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e60a5e15-6a4f-48c3-94ef-9711b35e683d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "copying koolaid.bin from /Users/apple/Rath Labs/ComputerScience/CODE/allPython/Python/A.I/DeepQReinforcementLearning/RL stablebaselines package/Breakout_AI/ROMS/Kool-Aid Man (Kool Aid Pitcher Man) (1983) (M Network, Stephen Tatsumi, Jane Terjung - Kool Aid) (MT4648) ~.bin to /opt/anaconda3/lib/python3.8/site-packages/atari_py/atari_roms/koolaid.bin\n",
      "copying alien.bin from /Users/apple/Rath Labs/ComputerScience/CODE/allPython/Python/A.I/DeepQReinforcementLearning/RL stablebaselines package/Breakout_AI/ROMS/Alien (1982) (20th Century Fox Video Games, Douglas 'Dallas North' Neubauer) (11006) ~.bin to /opt/anaconda3/lib/python3.8/site-packages/atari_py/atari_roms/alien.bin\n",
      "copying demon_attack.bin from /Users/apple/Rath Labs/ComputerScience/CODE/allPython/Python/A.I/DeepQReinforcementLearning/RL stablebaselines package/Breakout_AI/ROMS/Demon Attack (Death from Above) (1982) (Imagic, Rob Fulop) (720000-200, 720101-1B, 720101-1C, IA3200, IA3200C, IX-006-04) ~.bin to /opt/anaconda3/lib/python3.8/site-packages/atari_py/atari_roms/demon_attack.bin\n",
      "copying crazy_climber.bin from /Users/apple/Rath Labs/ComputerScience/CODE/allPython/Python/A.I/DeepQReinforcementLearning/RL stablebaselines package/Breakout_AI/ROMS/Crazy Climber (1983) (Atari - Roklan, Joe Gaucher, Alex Leavens) (CX2683) ~.bin to /opt/anaconda3/lib/python3.8/site-packages/atari_py/atari_roms/crazy_climber.bin\n",
      "copying video_pinball.bin from /Users/apple/Rath Labs/ComputerScience/CODE/allPython/Python/A.I/DeepQReinforcementLearning/RL stablebaselines package/Breakout_AI/ROMS/Pinball (AKA Video Pinball) (Zellers).bin to /opt/anaconda3/lib/python3.8/site-packages/atari_py/atari_roms/video_pinball.bin\n",
      "copying yars_revenge.bin from /Users/apple/Rath Labs/ComputerScience/CODE/allPython/Python/A.I/DeepQReinforcementLearning/RL stablebaselines package/Breakout_AI/ROMS/Yars' Revenge (Time Freeze) (1982) (Atari, Howard Scott Warshaw - Sears) (CX2655 - 49-75167) ~.bin to /opt/anaconda3/lib/python3.8/site-packages/atari_py/atari_roms/yars_revenge.bin\n",
      "copying donkey_kong.bin from /Users/apple/Rath Labs/ComputerScience/CODE/allPython/Python/A.I/DeepQReinforcementLearning/RL stablebaselines package/Breakout_AI/ROMS/Donkey Kong (1982) (Coleco - Woodside Design Associates - Imaginative Systems Software, Garry Kitchen) (2451) ~.bin to /opt/anaconda3/lib/python3.8/site-packages/atari_py/atari_roms/donkey_kong.bin\n",
      "copying carnival.bin from /Users/apple/Rath Labs/ComputerScience/CODE/allPython/Python/A.I/DeepQReinforcementLearning/RL stablebaselines package/Breakout_AI/ROMS/Carnival (1982) (Coleco - Woodside Design Associates, Steve 'Jessica Stevens' Kitchen) (2468) ~.bin to /opt/anaconda3/lib/python3.8/site-packages/atari_py/atari_roms/carnival.bin\n",
      "copying defender.bin from /Users/apple/Rath Labs/ComputerScience/CODE/allPython/Python/A.I/DeepQReinforcementLearning/RL stablebaselines package/Breakout_AI/ROMS/Defender (1982) (Atari, Robert C. Polaro, Alan J. Murphy - Sears) (CX2609 - 49-75186) ~.bin to /opt/anaconda3/lib/python3.8/site-packages/atari_py/atari_roms/defender.bin\n",
      "copying gopher.bin from /Users/apple/Rath Labs/ComputerScience/CODE/allPython/Python/A.I/DeepQReinforcementLearning/RL stablebaselines package/Breakout_AI/ROMS/Gopher (Gopher Attack) (1982) (U.S. Games Corporation - JWDA, Sylvia Day, Todd Marshall, Robin McDaniel, Henry Will IV) (VC2001) ~.bin to /opt/anaconda3/lib/python3.8/site-packages/atari_py/atari_roms/gopher.bin\n",
      "copying krull.bin from /Users/apple/Rath Labs/ComputerScience/CODE/allPython/Python/A.I/DeepQReinforcementLearning/RL stablebaselines package/Breakout_AI/ROMS/Krull (1983) (Atari, Jerome Domurat, Dave Staugas) (CX2682) ~.bin to /opt/anaconda3/lib/python3.8/site-packages/atari_py/atari_roms/krull.bin\n",
      "copying pacman.bin from /Users/apple/Rath Labs/ComputerScience/CODE/allPython/Python/A.I/DeepQReinforcementLearning/RL stablebaselines package/Breakout_AI/ROMS/Pac-Man (1982) (Atari, Tod Frye) (CX2646) (PAL).bin to /opt/anaconda3/lib/python3.8/site-packages/atari_py/atari_roms/pacman.bin\n",
      "copying surround.bin from /Users/apple/Rath Labs/ComputerScience/CODE/allPython/Python/A.I/DeepQReinforcementLearning/RL stablebaselines package/Breakout_AI/ROMS/Surround (32 in 1) (Bit Corporation) (R320).bin to /opt/anaconda3/lib/python3.8/site-packages/atari_py/atari_roms/surround.bin\n",
      "copying lost_luggage.bin from /Users/apple/Rath Labs/ComputerScience/CODE/allPython/Python/A.I/DeepQReinforcementLearning/RL stablebaselines package/Breakout_AI/ROMS/Lost Luggage (Airport Mayhem) (1982) (Apollo - Games by Apollo, Larry Minor, Ernie Runyon, Ed Salvo) (AP-2004) [no opening scene] ~.bin to /opt/anaconda3/lib/python3.8/site-packages/atari_py/atari_roms/lost_luggage.bin\n",
      "copying pong.bin from /Users/apple/Rath Labs/ComputerScience/CODE/allPython/Python/A.I/DeepQReinforcementLearning/RL stablebaselines package/Breakout_AI/ROMS/Video Olympics - Pong Sports (Paddle) (1977) (Atari, Joe Decuir - Sears) (CX2621 - 99806, 6-99806, 49-75104) ~.bin to /opt/anaconda3/lib/python3.8/site-packages/atari_py/atari_roms/pong.bin\n",
      "copying keystone_kapers.bin from /Users/apple/Rath Labs/ComputerScience/CODE/allPython/Python/A.I/DeepQReinforcementLearning/RL stablebaselines package/Breakout_AI/ROMS/Keystone Kapers - Raueber und Gendarm (1983) (Activision, Garry Kitchen - Ariola) (EAX-025, EAX-025-04I - 711 025-725) (PAL).bin to /opt/anaconda3/lib/python3.8/site-packages/atari_py/atari_roms/keystone_kapers.bin\n",
      "copying kung_fu_master.bin from /Users/apple/Rath Labs/ComputerScience/CODE/allPython/Python/A.I/DeepQReinforcementLearning/RL stablebaselines package/Breakout_AI/ROMS/Kung-Fu Master (1987) (Activision - Imagineering, Dan Kitchen, Garry Kitchen) (AG-039-04) ~.bin to /opt/anaconda3/lib/python3.8/site-packages/atari_py/atari_roms/kung_fu_master.bin\n",
      "copying trondead.bin from /Users/apple/Rath Labs/ComputerScience/CODE/allPython/Python/A.I/DeepQReinforcementLearning/RL stablebaselines package/Breakout_AI/ROMS/TRON - Deadly Discs (TRON Joystick) (1983) (M Network - INTV - APh Technological Consulting, Jeff Ronne, Brett Stutz) (MT5662) ~.bin to /opt/anaconda3/lib/python3.8/site-packages/atari_py/atari_roms/trondead.bin\n",
      "copying air_raid.bin from /Users/apple/Rath Labs/ComputerScience/CODE/allPython/Python/A.I/DeepQReinforcementLearning/RL stablebaselines package/Breakout_AI/ROMS/Air Raid (Men-A-Vision) (PAL) ~.bin to /opt/anaconda3/lib/python3.8/site-packages/atari_py/atari_roms/air_raid.bin\n",
      "copying name_this_game.bin from /Users/apple/Rath Labs/ComputerScience/CODE/allPython/Python/A.I/DeepQReinforcementLearning/RL stablebaselines package/Breakout_AI/ROMS/Name This Game (Guardians of Treasure) (1983) (U.S. Games Corporation - JWDA, Roger Booth, Sylvia Day, Ron Dubren, Todd Marshall, Robin McDaniel, Wes Trager, Henry Will IV) (VC1007) ~.bin to /opt/anaconda3/lib/python3.8/site-packages/atari_py/atari_roms/name_this_game.bin\n",
      "copying king_kong.bin from /Users/apple/Rath Labs/ComputerScience/CODE/allPython/Python/A.I/DeepQReinforcementLearning/RL stablebaselines package/Breakout_AI/ROMS/King Kong (1982) (Tigervision - Software Electronics Corporation, Karl T. Olinger - Teldec) (7-001 - 3.60001 VE) (PAL).bin to /opt/anaconda3/lib/python3.8/site-packages/atari_py/atari_roms/king_kong.bin\n",
      "copying qbert.bin from /Users/apple/Rath Labs/ComputerScience/CODE/allPython/Python/A.I/DeepQReinforcementLearning/RL stablebaselines package/Breakout_AI/ROMS/Q-bert (1983) (Parker Brothers - Western Technologies, Dave Hampton, Tom Sloper) (PB5360) ~.bin to /opt/anaconda3/lib/python3.8/site-packages/atari_py/atari_roms/qbert.bin\n",
      "copying robotank.bin from /Users/apple/Rath Labs/ComputerScience/CODE/allPython/Python/A.I/DeepQReinforcementLearning/RL stablebaselines package/Breakout_AI/ROMS/Robot Tank (Robotank) (1983) (Activision, Alan Miller) (AZ-028, AG-028-04) ~.bin to /opt/anaconda3/lib/python3.8/site-packages/atari_py/atari_roms/robotank.bin\n",
      "copying skiing.bin from /Users/apple/Rath Labs/ComputerScience/CODE/allPython/Python/A.I/DeepQReinforcementLearning/RL stablebaselines package/Breakout_AI/ROMS/Skiing - Le Ski (1980) (Activision, Bob Whitehead) (AG-005, CAG-005, AG-005-04) ~.bin to /opt/anaconda3/lib/python3.8/site-packages/atari_py/atari_roms/skiing.bin\n",
      "copying hero.bin from /Users/apple/Rath Labs/ComputerScience/CODE/allPython/Python/A.I/DeepQReinforcementLearning/RL stablebaselines package/Breakout_AI/ROMS/H.E.R.O. (1984) (Activision, John Van Ryzin) (AZ-036-04) ~.bin to /opt/anaconda3/lib/python3.8/site-packages/atari_py/atari_roms/hero.bin\n",
      "copying star_gunner.bin from /Users/apple/Rath Labs/ComputerScience/CODE/allPython/Python/A.I/DeepQReinforcementLearning/RL stablebaselines package/Breakout_AI/ROMS/Stargunner (1983) (Telesys, Alex Leavens) (1005) ~.bin to /opt/anaconda3/lib/python3.8/site-packages/atari_py/atari_roms/star_gunner.bin\n",
      "copying tutankham.bin from /Users/apple/Rath Labs/ComputerScience/CODE/allPython/Python/A.I/DeepQReinforcementLearning/RL stablebaselines package/Breakout_AI/ROMS/Tutankham (1983) (Parker Brothers, Dave Engman, Dawn Stockbridge) (PB5340) ~.bin to /opt/anaconda3/lib/python3.8/site-packages/atari_py/atari_roms/tutankham.bin\n",
      "copying gravitar.bin from /Users/apple/Rath Labs/ComputerScience/CODE/allPython/Python/A.I/DeepQReinforcementLearning/RL stablebaselines package/Breakout_AI/ROMS/Gravitar (1983) (Atari, Dan Hitchens, Mimi Nyden) (CX2685) ~.bin to /opt/anaconda3/lib/python3.8/site-packages/atari_py/atari_roms/gravitar.bin\n",
      "copying jamesbond.bin from /Users/apple/Rath Labs/ComputerScience/CODE/allPython/Python/A.I/DeepQReinforcementLearning/RL stablebaselines package/Breakout_AI/ROMS/James Bond 007 (James Bond Agent 007) (1984) (Parker Brothers - On-Time Software, Joe Gaucher, Louis Marbel) (PB5110) ~.bin to /opt/anaconda3/lib/python3.8/site-packages/atari_py/atari_roms/jamesbond.bin\n",
      "copying montezuma_revenge.bin from /Users/apple/Rath Labs/ComputerScience/CODE/allPython/Python/A.I/DeepQReinforcementLearning/RL stablebaselines package/Breakout_AI/ROMS/Montezuma's Revenge - Featuring Panama Joe (1984) (Parker Brothers - JWDA, Henry Will IV) (PB5760) ~.bin to /opt/anaconda3/lib/python3.8/site-packages/atari_py/atari_roms/montezuma_revenge.bin\n",
      "copying venture.bin from /Users/apple/Rath Labs/ComputerScience/CODE/allPython/Python/A.I/DeepQReinforcementLearning/RL stablebaselines package/Breakout_AI/ROMS/Venture (1982) (Coleco, Joseph Biel) (2457) ~.bin to /opt/anaconda3/lib/python3.8/site-packages/atari_py/atari_roms/venture.bin\n",
      "copying pitfall.bin from /Users/apple/Rath Labs/ComputerScience/CODE/allPython/Python/A.I/DeepQReinforcementLearning/RL stablebaselines package/Breakout_AI/ROMS/Pitfall! - Pitfall Harry's Jungle Adventure (Jungle Runner) (1982) (Activision, David Crane) (AX-018, AX-018-04) ~.bin to /opt/anaconda3/lib/python3.8/site-packages/atari_py/atari_roms/pitfall.bin\n",
      "copying laser_gates.bin from /Users/apple/Rath Labs/ComputerScience/CODE/allPython/Python/A.I/DeepQReinforcementLearning/RL stablebaselines package/Breakout_AI/ROMS/Laser Gates (AKA Innerspace) (1983) (Imagic, Dan Oliver) (720118-2A, 13208, EIX-007-04I) (PAL).bin to /opt/anaconda3/lib/python3.8/site-packages/atari_py/atari_roms/laser_gates.bin\n",
      "copying tennis.bin from /Users/apple/Rath Labs/ComputerScience/CODE/allPython/Python/A.I/DeepQReinforcementLearning/RL stablebaselines package/Breakout_AI/ROMS/Tennis - Le Tennis (1981) (Activision, Alan Miller) (AG-007, CAG-007) ~.bin to /opt/anaconda3/lib/python3.8/site-packages/atari_py/atari_roms/tennis.bin\n",
      "copying space_invaders.bin from /Users/apple/Rath Labs/ComputerScience/CODE/allPython/Python/A.I/DeepQReinforcementLearning/RL stablebaselines package/Breakout_AI/ROMS/Space Invaders (1980) (Atari, Richard Maurer - Sears) (CX2632 - 49-75153) ~.bin to /opt/anaconda3/lib/python3.8/site-packages/atari_py/atari_roms/space_invaders.bin\n",
      "copying mr_do.bin from /Users/apple/Rath Labs/ComputerScience/CODE/allPython/Python/A.I/DeepQReinforcementLearning/RL stablebaselines package/Breakout_AI/ROMS/Mr. Do! (1983) (CBS Electronics, Ed English) (4L4478) (PAL).bin to /opt/anaconda3/lib/python3.8/site-packages/atari_py/atari_roms/mr_do.bin\n",
      "copying up_n_down.bin from /Users/apple/Rath Labs/ComputerScience/CODE/allPython/Python/A.I/DeepQReinforcementLearning/RL stablebaselines package/Breakout_AI/ROMS/Up 'n Down (1984) (SEGA - Beck-Tech, Steve Beck, Phat Ho) (009-01) ~.bin to /opt/anaconda3/lib/python3.8/site-packages/atari_py/atari_roms/up_n_down.bin\n",
      "copying kaboom.bin from /Users/apple/Rath Labs/ComputerScience/CODE/allPython/Python/A.I/DeepQReinforcementLearning/RL stablebaselines package/Breakout_AI/ROMS/Kaboom! (Paddle) (1981) (Activision, Larry Kaplan, David Crane) (AG-010, AG-010-04) ~.bin to /opt/anaconda3/lib/python3.8/site-packages/atari_py/atari_roms/kaboom.bin\n",
      "copying galaxian.bin from /Users/apple/Rath Labs/ComputerScience/CODE/allPython/Python/A.I/DeepQReinforcementLearning/RL stablebaselines package/Breakout_AI/ROMS/Galaxian (1983) (Atari - GCC, Mark Ackerman, Tom Calderwood, Glenn Parker) (CX2684) ~.bin to /opt/anaconda3/lib/python3.8/site-packages/atari_py/atari_roms/galaxian.bin\n",
      "copying riverraid.bin from /Users/apple/Rath Labs/ComputerScience/CODE/allPython/Python/A.I/DeepQReinforcementLearning/RL stablebaselines package/Breakout_AI/ROMS/River Raid (1982) (Activision, Carol Shaw) (AX-020, AX-020-04) ~.bin to /opt/anaconda3/lib/python3.8/site-packages/atari_py/atari_roms/riverraid.bin\n",
      "copying enduro.bin from /Users/apple/Rath Labs/ComputerScience/CODE/allPython/Python/A.I/DeepQReinforcementLearning/RL stablebaselines package/Breakout_AI/ROMS/Enduro (1983) (Activision, Larry Miller) (AX-026, AX-026-04) ~.bin to /opt/anaconda3/lib/python3.8/site-packages/atari_py/atari_roms/enduro.bin\n",
      "copying amidar.bin from /Users/apple/Rath Labs/ComputerScience/CODE/allPython/Python/A.I/DeepQReinforcementLearning/RL stablebaselines package/Breakout_AI/ROMS/Amidar (1982) (Parker Brothers, Ed Temple) (PB5310) ~.bin to /opt/anaconda3/lib/python3.8/site-packages/atari_py/atari_roms/amidar.bin\n",
      "copying bowling.bin from /Users/apple/Rath Labs/ComputerScience/CODE/allPython/Python/A.I/DeepQReinforcementLearning/RL stablebaselines package/Breakout_AI/ROMS/Bowling (1979) (Atari, Larry Kaplan - Sears) (CX2628 - 6-99842, 49-75117) ~.bin to /opt/anaconda3/lib/python3.8/site-packages/atari_py/atari_roms/bowling.bin\n",
      "copying atlantis.bin from /Users/apple/Rath Labs/ComputerScience/CODE/allPython/Python/A.I/DeepQReinforcementLearning/RL stablebaselines package/Breakout_AI/ROMS/Atlantis (Lost City of Atlantis) (1982) (Imagic, Dennis Koble) (720103-1A, 720103-1B, IA3203, IX-010-04) ~.bin to /opt/anaconda3/lib/python3.8/site-packages/atari_py/atari_roms/atlantis.bin\n",
      "copying breakout.bin from /Users/apple/Rath Labs/ComputerScience/CODE/allPython/Python/A.I/DeepQReinforcementLearning/RL stablebaselines package/Breakout_AI/ROMS/Breakout - Breakaway IV (Paddle) (1978) (Atari, Brad Stewart - Sears) (CX2622 - 6-99813, 49-75107) ~.bin to /opt/anaconda3/lib/python3.8/site-packages/atari_py/atari_roms/breakout.bin\n",
      "copying phoenix.bin from /Users/apple/Rath Labs/ComputerScience/CODE/allPython/Python/A.I/DeepQReinforcementLearning/RL stablebaselines package/Breakout_AI/ROMS/Phoenix (1983) (Atari - GCC, Mike Feinstein, John Mracek) (CX2673) ~.bin to /opt/anaconda3/lib/python3.8/site-packages/atari_py/atari_roms/phoenix.bin\n",
      "copying asterix.bin from /Users/apple/Rath Labs/ComputerScience/CODE/allPython/Python/A.I/DeepQReinforcementLearning/RL stablebaselines package/Breakout_AI/ROMS/Asterix (AKA Taz) (07-27-1983) (Atari, Jerome Domurat, Steve Woita) (CX2696) (Prototype).bin to /opt/anaconda3/lib/python3.8/site-packages/atari_py/atari_roms/asterix.bin\n",
      "copying frostbite.bin from /Users/apple/Rath Labs/ComputerScience/CODE/allPython/Python/A.I/DeepQReinforcementLearning/RL stablebaselines package/Breakout_AI/ROMS/Frostbite (1983) (Activision, Steve Cartwright) (AX-031) ~.bin to /opt/anaconda3/lib/python3.8/site-packages/atari_py/atari_roms/frostbite.bin\n",
      "copying seaquest.bin from /Users/apple/Rath Labs/ComputerScience/CODE/allPython/Python/A.I/DeepQReinforcementLearning/RL stablebaselines package/Breakout_AI/ROMS/Seaquest (1983) (Activision, Steve Cartwright) (AX-022) ~.bin to /opt/anaconda3/lib/python3.8/site-packages/atari_py/atari_roms/seaquest.bin\n",
      "copying road_runner.bin from patched version of /Users/apple/Rath Labs/ComputerScience/CODE/allPython/Python/A.I/DeepQReinforcementLearning/RL stablebaselines package/Breakout_AI/ROMS/Road Runner (1989) (Atari - Bobco, Robert C. Polaro) (CX2663) ~.bin to /opt/anaconda3/lib/python3.8/site-packages/atari_py/atari_roms/road_runner.bin\n",
      "copying berzerk.bin from /Users/apple/Rath Labs/ComputerScience/CODE/allPython/Python/A.I/DeepQReinforcementLearning/RL stablebaselines package/Breakout_AI/ROMS/Berzerk (1982) (Atari, Dan Hitchens - Sears) (CX2650 - 49-75168) ~.bin to /opt/anaconda3/lib/python3.8/site-packages/atari_py/atari_roms/berzerk.bin\n",
      "copying ms_pacman.bin from /Users/apple/Rath Labs/ComputerScience/CODE/allPython/Python/A.I/DeepQReinforcementLearning/RL stablebaselines package/Breakout_AI/ROMS/Ms. Pac-Man (1983) (Atari - GCC, Mark Ackerman, Glenn Parker) (CX2675) ~.bin to /opt/anaconda3/lib/python3.8/site-packages/atari_py/atari_roms/ms_pacman.bin\n",
      "copying centipede.bin from /Users/apple/Rath Labs/ComputerScience/CODE/allPython/Python/A.I/DeepQReinforcementLearning/RL stablebaselines package/Breakout_AI/ROMS/Centipede (1983) (Atari - GCC) (CX2676) ~.bin to /opt/anaconda3/lib/python3.8/site-packages/atari_py/atari_roms/centipede.bin\n",
      "copying elevator_action.bin from /Users/apple/Rath Labs/ComputerScience/CODE/allPython/Python/A.I/DeepQReinforcementLearning/RL stablebaselines package/Breakout_AI/ROMS/Elevator Action (1983) (Atari, Dan Hitchens) (CX26126) (Prototype) ~.bin to /opt/anaconda3/lib/python3.8/site-packages/atari_py/atari_roms/elevator_action.bin\n",
      "copying double_dunk.bin from /Users/apple/Rath Labs/ComputerScience/CODE/allPython/Python/A.I/DeepQReinforcementLearning/RL stablebaselines package/Breakout_AI/ROMS/Double Dunk (Super Basketball) (1989) (Atari, Matthew L. Hubbard) (CX26159) ~.bin to /opt/anaconda3/lib/python3.8/site-packages/atari_py/atari_roms/double_dunk.bin\n",
      "copying assault.bin from /Users/apple/Rath Labs/ComputerScience/CODE/allPython/Python/A.I/DeepQReinforcementLearning/RL stablebaselines package/Breakout_AI/ROMS/Assault (AKA Sky Alien) (1983) (Bomb - Onbase) (CA281).bin to /opt/anaconda3/lib/python3.8/site-packages/atari_py/atari_roms/assault.bin\n",
      "copying ice_hockey.bin from /Users/apple/Rath Labs/ComputerScience/CODE/allPython/Python/A.I/DeepQReinforcementLearning/RL stablebaselines package/Breakout_AI/ROMS/Ice Hockey - Le Hockey Sur Glace (1981) (Activision, Alan Miller) (AX-012, CAX-012, AX-012-04) ~.bin to /opt/anaconda3/lib/python3.8/site-packages/atari_py/atari_roms/ice_hockey.bin\n",
      "copying zaxxon.bin from /Users/apple/Rath Labs/ComputerScience/CODE/allPython/Python/A.I/DeepQReinforcementLearning/RL stablebaselines package/Breakout_AI/ROMS/Zaxxon (1983) (Coleco) (2454) ~.bin to /opt/anaconda3/lib/python3.8/site-packages/atari_py/atari_roms/zaxxon.bin\n",
      "copying beam_rider.bin from /Users/apple/Rath Labs/ComputerScience/CODE/allPython/Python/A.I/DeepQReinforcementLearning/RL stablebaselines package/Breakout_AI/ROMS/Beamrider (1984) (Activision - Cheshire Engineering, David Rolfe, Larry Zwick) (AZ-037-04) ~.bin to /opt/anaconda3/lib/python3.8/site-packages/atari_py/atari_roms/beam_rider.bin\n",
      "copying sir_lancelot.bin from /Users/apple/Rath Labs/ComputerScience/CODE/allPython/Python/A.I/DeepQReinforcementLearning/RL stablebaselines package/Breakout_AI/ROMS/Sir Lancelot (1983) (Xonox - K-Tel Software - Product Guild, Anthony R. Henderson) (99006, 6220) (PAL).bin to /opt/anaconda3/lib/python3.8/site-packages/atari_py/atari_roms/sir_lancelot.bin\n",
      "copying wizard_of_wor.bin from /Users/apple/Rath Labs/ComputerScience/CODE/allPython/Python/A.I/DeepQReinforcementLearning/RL stablebaselines package/Breakout_AI/ROMS/Wizard of Wor (1982) (CBS Electronics - Roklan, Joe Hellesen, Joe Wagner) (M8774, M8794) ~.bin to /opt/anaconda3/lib/python3.8/site-packages/atari_py/atari_roms/wizard_of_wor.bin\n",
      "copying bank_heist.bin from /Users/apple/Rath Labs/ComputerScience/CODE/allPython/Python/A.I/DeepQReinforcementLearning/RL stablebaselines package/Breakout_AI/ROMS/Bank Heist (Bonnie & Clyde, Cops 'n' Robbers, Hold-Up, Roaring 20's) (1983) (20th Century Fox Video Games, Bill Aspromonte) (11012) ~.bin to /opt/anaconda3/lib/python3.8/site-packages/atari_py/atari_roms/bank_heist.bin\n",
      "copying private_eye.bin from /Users/apple/Rath Labs/ComputerScience/CODE/allPython/Python/A.I/DeepQReinforcementLearning/RL stablebaselines package/Breakout_AI/ROMS/Private Eye (1984) (Activision, Bob Whitehead) (AG-034-04) ~.bin to /opt/anaconda3/lib/python3.8/site-packages/atari_py/atari_roms/private_eye.bin\n",
      "copying battle_zone.bin from /Users/apple/Rath Labs/ComputerScience/CODE/allPython/Python/A.I/DeepQReinforcementLearning/RL stablebaselines package/Breakout_AI/ROMS/Battlezone (1983) (Atari - GCC, Mike Feinstein, Brad Rice) (CX2681) ~.bin to /opt/anaconda3/lib/python3.8/site-packages/atari_py/atari_roms/battle_zone.bin\n",
      "copying journey_escape.bin from /Users/apple/Rath Labs/ComputerScience/CODE/allPython/Python/A.I/DeepQReinforcementLearning/RL stablebaselines package/Breakout_AI/ROMS/Journey Escape (1983) (Data Age, J. Ray Dettling) (112-006) ~.bin to /opt/anaconda3/lib/python3.8/site-packages/atari_py/atari_roms/journey_escape.bin\n",
      "copying kangaroo.bin from /Users/apple/Rath Labs/ComputerScience/CODE/allPython/Python/A.I/DeepQReinforcementLearning/RL stablebaselines package/Breakout_AI/ROMS/Kangaroo (1983) (Atari - GCC, Kevin Osborn) (CX2689) ~.bin to /opt/anaconda3/lib/python3.8/site-packages/atari_py/atari_roms/kangaroo.bin\n",
      "copying boxing.bin from /Users/apple/Rath Labs/ComputerScience/CODE/allPython/Python/A.I/DeepQReinforcementLearning/RL stablebaselines package/Breakout_AI/ROMS/Boxing - La Boxe (1980) (Activision, Bob Whitehead) (AG-002, CAG-002, AG-002-04) ~.bin to /opt/anaconda3/lib/python3.8/site-packages/atari_py/atari_roms/boxing.bin\n",
      "copying fishing_derby.bin from /Users/apple/Rath Labs/ComputerScience/CODE/allPython/Python/A.I/DeepQReinforcementLearning/RL stablebaselines package/Breakout_AI/ROMS/Fishing Derby (1980) (Activision, David Crane) (AG-004) ~.bin to /opt/anaconda3/lib/python3.8/site-packages/atari_py/atari_roms/fishing_derby.bin\n",
      "copying freeway.bin from /Users/apple/Rath Labs/ComputerScience/CODE/allPython/Python/A.I/DeepQReinforcementLearning/RL stablebaselines package/Breakout_AI/ROMS/Freeway (1981) (Activision, David Crane) (AG-009, AG-009-04) ~.bin to /opt/anaconda3/lib/python3.8/site-packages/atari_py/atari_roms/freeway.bin\n",
      "copying pooyan.bin from /Users/apple/Rath Labs/ComputerScience/CODE/allPython/Python/A.I/DeepQReinforcementLearning/RL stablebaselines package/Breakout_AI/ROMS/Pooyan (1983) (Konami) (RC 100-X 02) ~.bin to /opt/anaconda3/lib/python3.8/site-packages/atari_py/atari_roms/pooyan.bin\n",
      "copying asteroids.bin from /Users/apple/Rath Labs/ComputerScience/CODE/allPython/Python/A.I/DeepQReinforcementLearning/RL stablebaselines package/Breakout_AI/ROMS/Asteroids (1981) (Atari, Brad Stewart - Sears) (CX2649 - 49-75163) [no copyright] ~.bin to /opt/anaconda3/lib/python3.8/site-packages/atari_py/atari_roms/asteroids.bin\n",
      "copying frogger.bin from /Users/apple/Rath Labs/ComputerScience/CODE/allPython/Python/A.I/DeepQReinforcementLearning/RL stablebaselines package/Breakout_AI/ROMS/Frogger (1982) (Parker Brothers, Ed English, David Lamkins) (PB5300) ~.bin to /opt/anaconda3/lib/python3.8/site-packages/atari_py/atari_roms/frogger.bin\n",
      "copying chopper_command.bin from /Users/apple/Rath Labs/ComputerScience/CODE/allPython/Python/A.I/DeepQReinforcementLearning/RL stablebaselines package/Breakout_AI/ROMS/Chopper Command (1982) (Activision, Bob Whitehead) (AX-015, AX-015-04) ~.bin to /opt/anaconda3/lib/python3.8/site-packages/atari_py/atari_roms/chopper_command.bin\n",
      "copying time_pilot.bin from /Users/apple/Rath Labs/ComputerScience/CODE/allPython/Python/A.I/DeepQReinforcementLearning/RL stablebaselines package/Breakout_AI/ROMS/Time Pilot (1983) (Coleco - Woodside Design Associates, Harley H. Puthuff Jr.) (2663) ~.bin to /opt/anaconda3/lib/python3.8/site-packages/atari_py/atari_roms/time_pilot.bin\n",
      "copying adventure.bin from /Users/apple/Rath Labs/ComputerScience/CODE/allPython/Python/A.I/DeepQReinforcementLearning/RL stablebaselines package/Breakout_AI/ROMS/Adventure (1980) (Atari, Warren Robinett) (CX2613, CX2613P) (PAL).bin to /opt/anaconda3/lib/python3.8/site-packages/atari_py/atari_roms/adventure.bin\n",
      "copying solaris.bin from /Users/apple/Rath Labs/ComputerScience/CODE/allPython/Python/A.I/DeepQReinforcementLearning/RL stablebaselines package/Breakout_AI/ROMS/Solaris (The Last Starfighter, Star Raiders II, Universe) (1986) (Atari, Douglas Neubauer, Mimi Nyden) (CX26136) ~.bin to /opt/anaconda3/lib/python3.8/site-packages/atari_py/atari_roms/solaris.bin\n"
     ]
    }
   ],
   "source": [
    "!python3 -m atari_py.import_roms \"/Users/apple/Rath Labs/ComputerScience/CODE/allPython/Python/A.I/DeepQReinforcementLearning/RL stablebaselines package/Breakout_AI\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ee07e32-df9b-4b0d-9dd9-4bf08ad79633",
   "metadata": {},
   "outputs": [],
   "source": [
    "environment = 'Breakout-v0'\n",
    "playGround = gym.make(environment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e29010d1-8f23-4a06-bafd-336b1cee1b61",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]]], dtype=uint8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "playGround.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8fadb6b4-7b28-4352-b1a3-91e2d42b8072",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discrete(4)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "playGround.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d302daee-1c16-4885-b30b-7a97df93f72c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box([[[0 0 0]\n",
       "  [0 0 0]\n",
       "  [0 0 0]\n",
       "  ...\n",
       "  [0 0 0]\n",
       "  [0 0 0]\n",
       "  [0 0 0]]\n",
       "\n",
       " [[0 0 0]\n",
       "  [0 0 0]\n",
       "  [0 0 0]\n",
       "  ...\n",
       "  [0 0 0]\n",
       "  [0 0 0]\n",
       "  [0 0 0]]\n",
       "\n",
       " [[0 0 0]\n",
       "  [0 0 0]\n",
       "  [0 0 0]\n",
       "  ...\n",
       "  [0 0 0]\n",
       "  [0 0 0]\n",
       "  [0 0 0]]\n",
       "\n",
       " ...\n",
       "\n",
       " [[0 0 0]\n",
       "  [0 0 0]\n",
       "  [0 0 0]\n",
       "  ...\n",
       "  [0 0 0]\n",
       "  [0 0 0]\n",
       "  [0 0 0]]\n",
       "\n",
       " [[0 0 0]\n",
       "  [0 0 0]\n",
       "  [0 0 0]\n",
       "  ...\n",
       "  [0 0 0]\n",
       "  [0 0 0]\n",
       "  [0 0 0]]\n",
       "\n",
       " [[0 0 0]\n",
       "  [0 0 0]\n",
       "  [0 0 0]\n",
       "  ...\n",
       "  [0 0 0]\n",
       "  [0 0 0]\n",
       "  [0 0 0]]], [[[255 255 255]\n",
       "  [255 255 255]\n",
       "  [255 255 255]\n",
       "  ...\n",
       "  [255 255 255]\n",
       "  [255 255 255]\n",
       "  [255 255 255]]\n",
       "\n",
       " [[255 255 255]\n",
       "  [255 255 255]\n",
       "  [255 255 255]\n",
       "  ...\n",
       "  [255 255 255]\n",
       "  [255 255 255]\n",
       "  [255 255 255]]\n",
       "\n",
       " [[255 255 255]\n",
       "  [255 255 255]\n",
       "  [255 255 255]\n",
       "  ...\n",
       "  [255 255 255]\n",
       "  [255 255 255]\n",
       "  [255 255 255]]\n",
       "\n",
       " ...\n",
       "\n",
       " [[255 255 255]\n",
       "  [255 255 255]\n",
       "  [255 255 255]\n",
       "  ...\n",
       "  [255 255 255]\n",
       "  [255 255 255]\n",
       "  [255 255 255]]\n",
       "\n",
       " [[255 255 255]\n",
       "  [255 255 255]\n",
       "  [255 255 255]\n",
       "  ...\n",
       "  [255 255 255]\n",
       "  [255 255 255]\n",
       "  [255 255 255]]\n",
       "\n",
       " [[255 255 255]\n",
       "  [255 255 255]\n",
       "  [255 255 255]\n",
       "  ...\n",
       "  [255 255 255]\n",
       "  [255 255 255]\n",
       "  [255 255 255]]], (210, 160, 3), uint8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "playGround.observation_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc5dd078-39c0-489f-92d1-46a9a1f0818d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:1 Score:1.0\n",
      "Episode:2 Score:1.0\n",
      "Episode:3 Score:0.0\n",
      "Episode:4 Score:0.0\n",
      "Episode:5 Score:1.0\n"
     ]
    }
   ],
   "source": [
    "episodes = 5\n",
    "for episode in range(1, episodes+1):\n",
    "    obs = playGround.reset()\n",
    "    done = False\n",
    "    score = 0\n",
    "    \n",
    "    while not done:\n",
    "        playGround.render()\n",
    "        action = playGround.action_space.sample()\n",
    "        obs, reward, done, info = playGround.step(action)\n",
    "        score += reward\n",
    "    print(\"Episode:{} Score:{}\".format(episode, score))\n",
    "playGround.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ab9a41-4e12-4c80-8a59-004436a3baf8",
   "metadata": {},
   "source": [
    "# Vectorize Environment\n",
    "#### and \n",
    "## Training the Model\n",
    "##### 100k TimeSteps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "338c6b59-efef-4239-97e7-98b6bf61818f",
   "metadata": {},
   "outputs": [],
   "source": [
    "playGround = make_atari_env('Breakout-v0', n_envs=4, seed=0)\n",
    "playGround = VecFrameStack(playGround, n_stack=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f5f9277-c649-4463-9b37-5f04248c5e74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env in a VecTransposeImage.\n"
     ]
    }
   ],
   "source": [
    "logPath = os.path.join('Training', 'Logs')\n",
    "laModel = A2C('CnnPolicy', playGround ,verbose=1, tensorboard_log=logPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "820771ce-b20c-4432-b8c4-a0abfe17b8e0",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to Training/Logs/A2C_1\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 280      |\n",
      "|    ep_rew_mean        | 1.5      |\n",
      "| time/                 |          |\n",
      "|    fps                | 53       |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 37       |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.39    |\n",
      "|    explained_variance | 0.0204   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | -0.0347  |\n",
      "|    value_loss         | 0.0622   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 278      |\n",
      "|    ep_rew_mean        | 1.52     |\n",
      "| time/                 |          |\n",
      "|    fps                | 54       |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 73       |\n",
      "|    total_timesteps    | 4000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.39    |\n",
      "|    explained_variance | 0.339    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | 0.113    |\n",
      "|    value_loss         | 0.348    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 284      |\n",
      "|    ep_rew_mean        | 1.62     |\n",
      "| time/                 |          |\n",
      "|    fps                | 56       |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 107      |\n",
      "|    total_timesteps    | 6000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.35    |\n",
      "|    explained_variance | 0.803    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | 0.235    |\n",
      "|    value_loss         | 0.0792   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 281      |\n",
      "|    ep_rew_mean        | 1.58     |\n",
      "| time/                 |          |\n",
      "|    fps                | 58       |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 136      |\n",
      "|    total_timesteps    | 8000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.23    |\n",
      "|    explained_variance | 0.82     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | 0.0622   |\n",
      "|    value_loss         | 0.0739   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 300      |\n",
      "|    ep_rew_mean        | 1.92     |\n",
      "| time/                 |          |\n",
      "|    fps                | 60       |\n",
      "|    iterations         | 500      |\n",
      "|    time_elapsed       | 165      |\n",
      "|    total_timesteps    | 10000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.11    |\n",
      "|    explained_variance | 0.89     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 499      |\n",
      "|    policy_loss        | -0.0784  |\n",
      "|    value_loss         | 0.0529   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 313      |\n",
      "|    ep_rew_mean        | 2.17     |\n",
      "| time/                 |          |\n",
      "|    fps                | 61       |\n",
      "|    iterations         | 600      |\n",
      "|    time_elapsed       | 194      |\n",
      "|    total_timesteps    | 12000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.15    |\n",
      "|    explained_variance | 0.749    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 599      |\n",
      "|    policy_loss        | -0.198   |\n",
      "|    value_loss         | 0.0662   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 314      |\n",
      "|    ep_rew_mean        | 2.17     |\n",
      "| time/                 |          |\n",
      "|    fps                | 62       |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 223      |\n",
      "|    total_timesteps    | 14000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.26    |\n",
      "|    explained_variance | 0.496    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | -0.124   |\n",
      "|    value_loss         | 0.0443   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 308      |\n",
      "|    ep_rew_mean        | 2.06     |\n",
      "| time/                 |          |\n",
      "|    fps                | 62       |\n",
      "|    iterations         | 800      |\n",
      "|    time_elapsed       | 254      |\n",
      "|    total_timesteps    | 16000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.954   |\n",
      "|    explained_variance | 0.57     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 799      |\n",
      "|    policy_loss        | -0.324   |\n",
      "|    value_loss         | 0.323    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 313      |\n",
      "|    ep_rew_mean        | 2.14     |\n",
      "| time/                 |          |\n",
      "|    fps                | 63       |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 283      |\n",
      "|    total_timesteps    | 18000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.08    |\n",
      "|    explained_variance | 0.915    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | -0.0246  |\n",
      "|    value_loss         | 0.021    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 317      |\n",
      "|    ep_rew_mean        | 2.23     |\n",
      "| time/                 |          |\n",
      "|    fps                | 63       |\n",
      "|    iterations         | 1000     |\n",
      "|    time_elapsed       | 314      |\n",
      "|    total_timesteps    | 20000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.948   |\n",
      "|    explained_variance | 0.944    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 999      |\n",
      "|    policy_loss        | 0.091    |\n",
      "|    value_loss         | 0.0394   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 312      |\n",
      "|    ep_rew_mean        | 2.15     |\n",
      "| time/                 |          |\n",
      "|    fps                | 63       |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 343      |\n",
      "|    total_timesteps    | 22000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.06    |\n",
      "|    explained_variance | 0.966    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | -0.0041  |\n",
      "|    value_loss         | 0.00394  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 306      |\n",
      "|    ep_rew_mean        | 2.04     |\n",
      "| time/                 |          |\n",
      "|    fps                | 64       |\n",
      "|    iterations         | 1200     |\n",
      "|    time_elapsed       | 372      |\n",
      "|    total_timesteps    | 24000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.09    |\n",
      "|    explained_variance | 0.965    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1199     |\n",
      "|    policy_loss        | -0.0983  |\n",
      "|    value_loss         | 0.0216   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 306      |\n",
      "|    ep_rew_mean        | 2.05     |\n",
      "| time/                 |          |\n",
      "|    fps                | 64       |\n",
      "|    iterations         | 1300     |\n",
      "|    time_elapsed       | 403      |\n",
      "|    total_timesteps    | 26000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.25    |\n",
      "|    explained_variance | 0.975    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1299     |\n",
      "|    policy_loss        | 0.025    |\n",
      "|    value_loss         | 0.0036   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 302      |\n",
      "|    ep_rew_mean        | 1.96     |\n",
      "| time/                 |          |\n",
      "|    fps                | 64       |\n",
      "|    iterations         | 1400     |\n",
      "|    time_elapsed       | 432      |\n",
      "|    total_timesteps    | 28000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.21    |\n",
      "|    explained_variance | 0.775    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1399     |\n",
      "|    policy_loss        | -0.0493  |\n",
      "|    value_loss         | 0.0095   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 303      |\n",
      "|    ep_rew_mean        | 1.99     |\n",
      "| time/                 |          |\n",
      "|    fps                | 64       |\n",
      "|    iterations         | 1500     |\n",
      "|    time_elapsed       | 461      |\n",
      "|    total_timesteps    | 30000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.972   |\n",
      "|    explained_variance | 0.912    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1499     |\n",
      "|    policy_loss        | 0.0809   |\n",
      "|    value_loss         | 0.0521   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 291      |\n",
      "|    ep_rew_mean        | 1.76     |\n",
      "| time/                 |          |\n",
      "|    fps                | 65       |\n",
      "|    iterations         | 1600     |\n",
      "|    time_elapsed       | 490      |\n",
      "|    total_timesteps    | 32000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.899   |\n",
      "|    explained_variance | 0.39     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1599     |\n",
      "|    policy_loss        | 0.0529   |\n",
      "|    value_loss         | 0.0568   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 293      |\n",
      "|    ep_rew_mean        | 1.82     |\n",
      "| time/                 |          |\n",
      "|    fps                | 65       |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 520      |\n",
      "|    total_timesteps    | 34000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.764   |\n",
      "|    explained_variance | 0.939    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | 0.0273   |\n",
      "|    value_loss         | 0.014    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 291       |\n",
      "|    ep_rew_mean        | 1.76      |\n",
      "| time/                 |           |\n",
      "|    fps                | 65        |\n",
      "|    iterations         | 1800      |\n",
      "|    time_elapsed       | 549       |\n",
      "|    total_timesteps    | 36000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.828    |\n",
      "|    explained_variance | 0.994     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1799      |\n",
      "|    policy_loss        | -0.000575 |\n",
      "|    value_loss         | 0.00495   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 293      |\n",
      "|    ep_rew_mean        | 1.75     |\n",
      "| time/                 |          |\n",
      "|    fps                | 65       |\n",
      "|    iterations         | 1900     |\n",
      "|    time_elapsed       | 578      |\n",
      "|    total_timesteps    | 38000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.917   |\n",
      "|    explained_variance | 0.989    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1899     |\n",
      "|    policy_loss        | 0.0453   |\n",
      "|    value_loss         | 0.00483  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 293      |\n",
      "|    ep_rew_mean        | 1.72     |\n",
      "| time/                 |          |\n",
      "|    fps                | 65       |\n",
      "|    iterations         | 2000     |\n",
      "|    time_elapsed       | 607      |\n",
      "|    total_timesteps    | 40000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.751   |\n",
      "|    explained_variance | 0.958    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1999     |\n",
      "|    policy_loss        | -0.0252  |\n",
      "|    value_loss         | 0.0116   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 303      |\n",
      "|    ep_rew_mean        | 1.89     |\n",
      "| time/                 |          |\n",
      "|    fps                | 65       |\n",
      "|    iterations         | 2100     |\n",
      "|    time_elapsed       | 637      |\n",
      "|    total_timesteps    | 42000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.818   |\n",
      "|    explained_variance | 0.997    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2099     |\n",
      "|    policy_loss        | 0.00119  |\n",
      "|    value_loss         | 0.00231  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 305      |\n",
      "|    ep_rew_mean        | 1.96     |\n",
      "| time/                 |          |\n",
      "|    fps                | 65       |\n",
      "|    iterations         | 2200     |\n",
      "|    time_elapsed       | 668      |\n",
      "|    total_timesteps    | 44000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.06    |\n",
      "|    explained_variance | -1.28    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2199     |\n",
      "|    policy_loss        | 0.000301 |\n",
      "|    value_loss         | 0.000404 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 307      |\n",
      "|    ep_rew_mean        | 2        |\n",
      "| time/                 |          |\n",
      "|    fps                | 65       |\n",
      "|    iterations         | 2300     |\n",
      "|    time_elapsed       | 697      |\n",
      "|    total_timesteps    | 46000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.89    |\n",
      "|    explained_variance | 0.971    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2299     |\n",
      "|    policy_loss        | 0.05     |\n",
      "|    value_loss         | 0.0207   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 300      |\n",
      "|    ep_rew_mean        | 1.9      |\n",
      "| time/                 |          |\n",
      "|    fps                | 65       |\n",
      "|    iterations         | 2400     |\n",
      "|    time_elapsed       | 727      |\n",
      "|    total_timesteps    | 48000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.915   |\n",
      "|    explained_variance | 0.981    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2399     |\n",
      "|    policy_loss        | 0.0345   |\n",
      "|    value_loss         | 0.00765  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 303      |\n",
      "|    ep_rew_mean        | 1.95     |\n",
      "| time/                 |          |\n",
      "|    fps                | 66       |\n",
      "|    iterations         | 2500     |\n",
      "|    time_elapsed       | 756      |\n",
      "|    total_timesteps    | 50000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.98    |\n",
      "|    explained_variance | 0.997    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2499     |\n",
      "|    policy_loss        | -0.00431 |\n",
      "|    value_loss         | 0.00187  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 307      |\n",
      "|    ep_rew_mean        | 2.01     |\n",
      "| time/                 |          |\n",
      "|    fps                | 66       |\n",
      "|    iterations         | 2600     |\n",
      "|    time_elapsed       | 785      |\n",
      "|    total_timesteps    | 52000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.926   |\n",
      "|    explained_variance | 0.997    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2599     |\n",
      "|    policy_loss        | -0.0184  |\n",
      "|    value_loss         | 0.00222  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 305      |\n",
      "|    ep_rew_mean        | 1.98     |\n",
      "| time/                 |          |\n",
      "|    fps                | 66       |\n",
      "|    iterations         | 2700     |\n",
      "|    time_elapsed       | 813      |\n",
      "|    total_timesteps    | 54000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.11    |\n",
      "|    explained_variance | 0.856    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2699     |\n",
      "|    policy_loss        | -0.0948  |\n",
      "|    value_loss         | 0.0138   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 303      |\n",
      "|    ep_rew_mean        | 1.97     |\n",
      "| time/                 |          |\n",
      "|    fps                | 66       |\n",
      "|    iterations         | 2800     |\n",
      "|    time_elapsed       | 843      |\n",
      "|    total_timesteps    | 56000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.13    |\n",
      "|    explained_variance | 0.997    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2799     |\n",
      "|    policy_loss        | 0.0236   |\n",
      "|    value_loss         | 0.000776 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 300      |\n",
      "|    ep_rew_mean        | 1.92     |\n",
      "| time/                 |          |\n",
      "|    fps                | 66       |\n",
      "|    iterations         | 2900     |\n",
      "|    time_elapsed       | 871      |\n",
      "|    total_timesteps    | 58000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.17    |\n",
      "|    explained_variance | 0.984    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2899     |\n",
      "|    policy_loss        | -0.0143  |\n",
      "|    value_loss         | 0.00252  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 295      |\n",
      "|    ep_rew_mean        | 1.83     |\n",
      "| time/                 |          |\n",
      "|    fps                | 66       |\n",
      "|    iterations         | 3000     |\n",
      "|    time_elapsed       | 900      |\n",
      "|    total_timesteps    | 60000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.955   |\n",
      "|    explained_variance | 0.923    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2999     |\n",
      "|    policy_loss        | -0.126   |\n",
      "|    value_loss         | 0.0528   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 305      |\n",
      "|    ep_rew_mean        | 2.05     |\n",
      "| time/                 |          |\n",
      "|    fps                | 66       |\n",
      "|    iterations         | 3100     |\n",
      "|    time_elapsed       | 929      |\n",
      "|    total_timesteps    | 62000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.21    |\n",
      "|    explained_variance | 0.768    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3099     |\n",
      "|    policy_loss        | -0.0665  |\n",
      "|    value_loss         | 0.0244   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 316      |\n",
      "|    ep_rew_mean        | 2.27     |\n",
      "| time/                 |          |\n",
      "|    fps                | 66       |\n",
      "|    iterations         | 3200     |\n",
      "|    time_elapsed       | 958      |\n",
      "|    total_timesteps    | 64000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.34    |\n",
      "|    explained_variance | -0.267   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3199     |\n",
      "|    policy_loss        | -0.0476  |\n",
      "|    value_loss         | 0.00261  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 321      |\n",
      "|    ep_rew_mean        | 2.37     |\n",
      "| time/                 |          |\n",
      "|    fps                | 66       |\n",
      "|    iterations         | 3300     |\n",
      "|    time_elapsed       | 987      |\n",
      "|    total_timesteps    | 66000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1       |\n",
      "|    explained_variance | 0.99     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3299     |\n",
      "|    policy_loss        | 0.00694  |\n",
      "|    value_loss         | 0.00501  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 331      |\n",
      "|    ep_rew_mean        | 2.57     |\n",
      "| time/                 |          |\n",
      "|    fps                | 66       |\n",
      "|    iterations         | 3400     |\n",
      "|    time_elapsed       | 1016     |\n",
      "|    total_timesteps    | 68000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.37    |\n",
      "|    explained_variance | -0.342   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3399     |\n",
      "|    policy_loss        | -0.0591  |\n",
      "|    value_loss         | 0.00326  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 336      |\n",
      "|    ep_rew_mean        | 2.61     |\n",
      "| time/                 |          |\n",
      "|    fps                | 67       |\n",
      "|    iterations         | 3500     |\n",
      "|    time_elapsed       | 1044     |\n",
      "|    total_timesteps    | 70000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.15    |\n",
      "|    explained_variance | 0.884    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3499     |\n",
      "|    policy_loss        | -0.23    |\n",
      "|    value_loss         | 0.0991   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 349      |\n",
      "|    ep_rew_mean        | 2.87     |\n",
      "| time/                 |          |\n",
      "|    fps                | 67       |\n",
      "|    iterations         | 3600     |\n",
      "|    time_elapsed       | 1073     |\n",
      "|    total_timesteps    | 72000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.528   |\n",
      "|    explained_variance | 0.639    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3599     |\n",
      "|    policy_loss        | 0.0798   |\n",
      "|    value_loss         | 0.133    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 372      |\n",
      "|    ep_rew_mean        | 3.39     |\n",
      "| time/                 |          |\n",
      "|    fps                | 67       |\n",
      "|    iterations         | 3700     |\n",
      "|    time_elapsed       | 1101     |\n",
      "|    total_timesteps    | 74000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.657   |\n",
      "|    explained_variance | 0.352    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3699     |\n",
      "|    policy_loss        | 0.112    |\n",
      "|    value_loss         | 0.364    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 380      |\n",
      "|    ep_rew_mean        | 3.61     |\n",
      "| time/                 |          |\n",
      "|    fps                | 67       |\n",
      "|    iterations         | 3800     |\n",
      "|    time_elapsed       | 1129     |\n",
      "|    total_timesteps    | 76000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.255   |\n",
      "|    explained_variance | 0.821    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3799     |\n",
      "|    policy_loss        | -0.0246  |\n",
      "|    value_loss         | 0.103    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 380      |\n",
      "|    ep_rew_mean        | 3.73     |\n",
      "| time/                 |          |\n",
      "|    fps                | 67       |\n",
      "|    iterations         | 3900     |\n",
      "|    time_elapsed       | 1157     |\n",
      "|    total_timesteps    | 78000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.385   |\n",
      "|    explained_variance | 0.808    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3899     |\n",
      "|    policy_loss        | -0.0249  |\n",
      "|    value_loss         | 0.073    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 386      |\n",
      "|    ep_rew_mean        | 3.92     |\n",
      "| time/                 |          |\n",
      "|    fps                | 67       |\n",
      "|    iterations         | 4000     |\n",
      "|    time_elapsed       | 1185     |\n",
      "|    total_timesteps    | 80000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.428   |\n",
      "|    explained_variance | 0.945    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3999     |\n",
      "|    policy_loss        | 0.11     |\n",
      "|    value_loss         | 0.088    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 399      |\n",
      "|    ep_rew_mean        | 4.16     |\n",
      "| time/                 |          |\n",
      "|    fps                | 67       |\n",
      "|    iterations         | 4100     |\n",
      "|    time_elapsed       | 1214     |\n",
      "|    total_timesteps    | 82000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.601   |\n",
      "|    explained_variance | 0.987    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4099     |\n",
      "|    policy_loss        | 0.026    |\n",
      "|    value_loss         | 0.0184   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 416      |\n",
      "|    ep_rew_mean        | 4.51     |\n",
      "| time/                 |          |\n",
      "|    fps                | 67       |\n",
      "|    iterations         | 4200     |\n",
      "|    time_elapsed       | 1241     |\n",
      "|    total_timesteps    | 84000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.543   |\n",
      "|    explained_variance | 0.809    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4199     |\n",
      "|    policy_loss        | 0.352    |\n",
      "|    value_loss         | 0.203    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 440      |\n",
      "|    ep_rew_mean        | 4.97     |\n",
      "| time/                 |          |\n",
      "|    fps                | 67       |\n",
      "|    iterations         | 4300     |\n",
      "|    time_elapsed       | 1269     |\n",
      "|    total_timesteps    | 86000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.933   |\n",
      "|    explained_variance | 0.96     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4299     |\n",
      "|    policy_loss        | 0.0457   |\n",
      "|    value_loss         | 0.024    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 450      |\n",
      "|    ep_rew_mean        | 5.16     |\n",
      "| time/                 |          |\n",
      "|    fps                | 67       |\n",
      "|    iterations         | 4400     |\n",
      "|    time_elapsed       | 1297     |\n",
      "|    total_timesteps    | 88000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.771   |\n",
      "|    explained_variance | 0.894    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4399     |\n",
      "|    policy_loss        | 0.207    |\n",
      "|    value_loss         | 0.195    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 468      |\n",
      "|    ep_rew_mean        | 5.45     |\n",
      "| time/                 |          |\n",
      "|    fps                | 67       |\n",
      "|    iterations         | 4500     |\n",
      "|    time_elapsed       | 1325     |\n",
      "|    total_timesteps    | 90000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.742   |\n",
      "|    explained_variance | 0.91     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4499     |\n",
      "|    policy_loss        | -0.0205  |\n",
      "|    value_loss         | 0.019    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 469      |\n",
      "|    ep_rew_mean        | 5.49     |\n",
      "| time/                 |          |\n",
      "|    fps                | 67       |\n",
      "|    iterations         | 4600     |\n",
      "|    time_elapsed       | 1354     |\n",
      "|    total_timesteps    | 92000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.903   |\n",
      "|    explained_variance | 0.535    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4599     |\n",
      "|    policy_loss        | -0.0519  |\n",
      "|    value_loss         | 0.0738   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 478      |\n",
      "|    ep_rew_mean        | 5.78     |\n",
      "| time/                 |          |\n",
      "|    fps                | 68       |\n",
      "|    iterations         | 4700     |\n",
      "|    time_elapsed       | 1381     |\n",
      "|    total_timesteps    | 94000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.648   |\n",
      "|    explained_variance | 0.396    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4699     |\n",
      "|    policy_loss        | -0.0204  |\n",
      "|    value_loss         | 0.191    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 490      |\n",
      "|    ep_rew_mean        | 6.06     |\n",
      "| time/                 |          |\n",
      "|    fps                | 68       |\n",
      "|    iterations         | 4800     |\n",
      "|    time_elapsed       | 1409     |\n",
      "|    total_timesteps    | 96000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.848   |\n",
      "|    explained_variance | 0.929    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4799     |\n",
      "|    policy_loss        | 0.0782   |\n",
      "|    value_loss         | 0.0292   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 497      |\n",
      "|    ep_rew_mean        | 6.28     |\n",
      "| time/                 |          |\n",
      "|    fps                | 68       |\n",
      "|    iterations         | 4900     |\n",
      "|    time_elapsed       | 1437     |\n",
      "|    total_timesteps    | 98000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.02    |\n",
      "|    explained_variance | 0.955    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4899     |\n",
      "|    policy_loss        | -0.0662  |\n",
      "|    value_loss         | 0.0244   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 491      |\n",
      "|    ep_rew_mean        | 6.26     |\n",
      "| time/                 |          |\n",
      "|    fps                | 68       |\n",
      "|    iterations         | 5000     |\n",
      "|    time_elapsed       | 1465     |\n",
      "|    total_timesteps    | 100000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.779   |\n",
      "|    explained_variance | 0.461    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4999     |\n",
      "|    policy_loss        | -0.0396  |\n",
      "|    value_loss         | 0.212    |\n",
      "------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.a2c.a2c.A2C at 0x13ebd0820>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "laModel.learn(total_timesteps=100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7edd02cf-ce2f-49fa-9ee0-18a01b5cda0c",
   "metadata": {},
   "source": [
    "# Saving the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "86073965-37c3-4ef9-a624-067840cfab1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/stable_baselines3/common/save_util.py:276: UserWarning: Path 'Training/SavedModels' does not exist. Will create it.\n",
      "  warnings.warn(f\"Path '{path.parent}' does not exist. Will create it.\")\n"
     ]
    }
   ],
   "source": [
    "a2cPath = os.path.join('Training', \n",
    "                       'SavedModels', \n",
    "                       'A2C_Breakout_Model_Mark1')\n",
    "laModel.save(a2cPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3291843e-5b95-4c7b-bf19-4e138b733d31",
   "metadata": {},
   "source": [
    "# Evaluation and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8afa29ab-47c7-45d1-a7a0-4f2336ab8034",
   "metadata": {},
   "outputs": [],
   "source": [
    "singlePlayGround = make_atari_env('Breakout-v0', n_envs=1, seed=0)\n",
    "singlePlayGround = VecFrameStack(singlePlayGround, n_stack=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7dfd5a9d-0562-4739-87c4-1baeb35db234",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6.4, 2.2)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_policy(laModel, singlePlayGround, n_eval_episodes=10, render=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7c29a067-29f3-45a8-a00f-fef9b3762db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "singlePlayGround.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9686bcaa-b436-4bef-96ee-e4d8e9b9a7a1",
   "metadata": {},
   "source": [
    "# Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6620fc18-16b3-4f03-8feb-303f0c1899ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Training/Logs/A2C_1'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainingLogPath = os.path.join(logPath, 'A2C_1')\n",
    "trainingLogPath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f5d3a0b6-a387-43e4-953e-4f0bfd151662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow installation not found - running with reduced feature set.\n",
      "\n",
      "NOTE: Using experimental fast data loading logic. To disable, pass\n",
      "    \"--load_fast=false\" and report issues on GitHub. More details:\n",
      "    https://github.com/tensorflow/tensorboard/issues/4784\n",
      "\n",
      "Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\n",
      "TensorBoard 2.7.0 at http://localhost:6006/ (Press CTRL+C to quit)\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "#!tensorboard --logdir={trainingLogPath}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dcd5a37-8d28-4187-b31e-1b3fc76cd6df",
   "metadata": {},
   "source": [
    "# Mark II - Better Model\n",
    "#### 2 Million TimeSteps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "87833333-2798-4226-92d1-af2f46c9f2e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env in a VecTransposeImage.\n"
     ]
    }
   ],
   "source": [
    "markII_path = os.path.join('Training', \n",
    "                           'SavedModels', \n",
    "                           'A2C_Breakout_Model_Mark2_2mTs')\n",
    "\n",
    "markII_Model = A2C.load(markII_path, singlePlayGround)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "53d8f782-f98c-4c7a-8183-943acccb22ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "singlePlayGround = make_atari_env('Breakout-v0', n_envs=1, seed=0)\n",
    "singlePlayGround = VecFrameStack(singlePlayGround, n_stack=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b3857200-f3fa-4462-b7cf-1ec154d9fd08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22.22, 9.056025618338323)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_policy(markII_Model, \n",
    "                singlePlayGround, \n",
    "                n_eval_episodes=50, \n",
    "                render=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "299168fb-2272-455d-8a44-3b853e1eeb45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:1 Score:[0.]\n",
      "Episode:2 Score:[5.]\n",
      "Episode:3 Score:[0.]\n",
      "Episode:4 Score:[0.]\n",
      "Episode:5 Score:[13.]\n",
      "Episode:6 Score:[0.]\n",
      "Episode:7 Score:[14.]\n",
      "Episode:8 Score:[0.]\n",
      "Episode:9 Score:[0.]\n",
      "Episode:10 Score:[0.]\n"
     ]
    }
   ],
   "source": [
    "episodes = 7\n",
    "for episode in range(1, episodes+1):\n",
    "    obs = singlePlayGround.reset()\n",
    "    done = False\n",
    "    score = 0\n",
    "    \n",
    "    while not done:\n",
    "        singlePlayGround.render()\n",
    "        #using the Model here\n",
    "        action, _ = markII_Model.predict(obs)\n",
    "        obs, reward, done, info = singlePlayGround.step(action)\n",
    "        score += reward\n",
    "    print(\"Episode:{} Score:{}\".format(episode, score))\n",
    "#singlePlayGround.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "968b14e1-6abc-4da3-9ef0-b85d5cda7a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "singlePlayGround.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c5a4b8-6931-4ca3-88bd-069fffcd0e85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
